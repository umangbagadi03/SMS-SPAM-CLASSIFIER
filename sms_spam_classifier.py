# -*- coding: utf-8 -*-
"""SMS SPAM CLASSIFIER.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_E5DKzSVUUPsMzxoSIu89kBvw7dA3aUo
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/projects/SMS SPAM CLASSIFIER

#RUN TO DOWNLOAD DEPENDENCIES
import joblib
import nltk
nltk.download('stopwords')

import pandas as pd

training_data = pd.read_csv("/content/drive/MyDrive/projects/SMS SPAM CLASSIFIER/training_data.csv")

training_data.head(10)

# convert the DataFrame to a NumPy array

data = training_data.to_numpy()
data

X = data[:, 0]
y = data[:, 1]
X.shape, y.shape

"""# Tokenization"""

# With the help of NLTK tokenize.regexp() module, we are able to extract the tokens from string by using regular expression with RegexpTokenizer() method.

from nltk.tokenize import RegexpTokenizer
tokenizer = RegexpTokenizer('\w+')

"""# Stopwords"""

from nltk.corpus import stopwords
sw = set(stopwords.words('english'))

"""# Tokenizing -> Stopwords Removal -> Stemming

"""

from nltk.stem import PorterStemmer
ps = PorterStemmer()

def stemming(sentence):
    sentence = sentence.lower()
    tokens = tokenizer.tokenize(sentence) 
    removed_stopwords = [w for w in tokens if w not in sw]
    stemmed_words = [ps.stem(token) for token in removed_stopwords]
    clean_sentence = ' '.join(stemmed_words)
    return clean_sentence

# GET A CLEAN DATASET
def getClean(document):
    d = []
    for doc in document:
        d.append(stemming(doc))
    return d

stemmed_doc = getClean(X)

"""# Count Vectorization

CountVectorizer means breaking down a sentence or any text into words by performing preprocessing tasks like converting all words to lowercase, thus removing special characters.

"""

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer()

vc = cv.fit_transform(stemmed_doc)
X = vc.todense()

"""# Splitting into training and testing data to calculate model accuracy

"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Implementing Naive Bayes' Algorithm

**Why We Using Naive Bayes as an Algorithms for Filtering the Email:-**

Naive Bayes work on dependent events and the probability of an event occurring in the future that can be detected from the previous occurring of the same event . This technique can be used to classify spam e-mails, words probabilities play the main rule here. If some words occur often in spam but not in ham, then this incoming e-mail is probably spam. Naive Bayes classifier technique has become a very popular method in mail filtering Email. Every word has certain probability of occurring in spam or ham email in its database. If the total of words probabilities exceeds a certain limit, the filter will mark the e-mail to either category. Here, only two categories are necessary: spam or ham.
"""

from sklearn.naive_bayes import MultinomialNB
model = MultinomialNB()
model.fit(X_train, y_train)
print(y_train)

"""# Model Accuracy

"""

model.score(X_test, y_test)

"""# Prediction on Test Data

"""

test_data = pd.read_csv('test_data.csv')

test = test_data.to_numpy()
test_messages = test[:, 0]
type(test)
test_messages.shape

def prepare(messages):
    d = getClean(messages)
    return cv.transform(d)

messages = prepare(test_messages)
y_pred = model.predict(messages)
test_data['ham_or_spam'] = y_pred
test_data

"""# Exporting to csv"""

test_data.to_csv('Predicted.csv')